{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read file json data_skill_tensor.json\n",
    "\n",
    "with open('data//train/data_skill_tensor.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "data_skill = [job['skills'] for job in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IT skill JDs\n",
    "def load_data_skill(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return list(data.values())\n",
    "\n",
    "skill1 = load_data_skill('data//train/IT_skill_JDs_p1.json')\n",
    "skill2 = load_data_skill('data/train/IT_skill_JDs_p1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nomalize_skill(skill):\n",
    "    for i in range(len(skill)):\n",
    "        skill[i] = [item.lower() for item in skill[i]]\n",
    "    \n",
    "    return skill\n",
    "\n",
    "data_skill = nomalize_skill(data_skill)\n",
    "skill1 = nomalize_skill(skill1)\n",
    "skill2 = nomalize_skill(skill2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate three list\n",
    "total_skill_jbs = data_skill + skill1 + skill2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contraction Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word-processing': 'word processing',\n",
       " 'ci': 'continuous integration',\n",
       " 'ci/cd': ['continuous integration', 'cd'],\n",
       " 'gke': 'google kubernetes engine',\n",
       " 'cv': 'computer vision',\n",
       " 'nlp': 'natural language processing',\n",
       " 'ms office applications': 'microsoft office',\n",
       " 'office 365': 'microsoft office',\n",
       " 'ms 365': 'microsoft office',\n",
       " 'office tools': 'microsoft office',\n",
       " 'asp.net mvc': 'asp.net',\n",
       " 'mvc application architecture': 'mvc',\n",
       " '.net technologies': '.net',\n",
       " '.net standard': '.net',\n",
       " '.net c#': ['c#', '.net'],\n",
       " 'c# .net core': ['c#', '.net core'],\n",
       " 'powershell cli': 'powershell',\n",
       " 'saas.': 'saas',\n",
       " 'deployment templates': 'templates',\n",
       " 'bi reporting': 'business intelligence reporting',\n",
       " 'ml frameworks': 'machine learning',\n",
       " 'backend java': 'java',\n",
       " 'java source': 'java',\n",
       " 'java 11': 'java',\n",
       " 'ddd': 'domain driven design',\n",
       " 'jcl': 'job control language',\n",
       " 'sops': 'standard operating procedure',\n",
       " 'cmdb': 'configuration management databases',\n",
       " 'san system': 'storage area network',\n",
       " 'san storage': 'storage area network',\n",
       " 'san': 'storage area networks',\n",
       " 'hv': 'high voltage',\n",
       " 'lv': 'low voltage',\n",
       " 'mfa': 'multi-factor authentication',\n",
       " 'edr': 'endpoint detection and response',\n",
       " 'siems': 'security information and event management',\n",
       " 'pd': 'pandas',\n",
       " 'oracle mysql': 'mysql',\n",
       " 'oracle sql developer': 'sql',\n",
       " 'win': 'windows',\n",
       " 'sql-based': 'sql',\n",
       " 'sql query': 'sql',\n",
       " 'sql querying': 'sql',\n",
       " 'sql queries': 'sql',\n",
       " 'azure ml': 'azure machine learning',\n",
       " 'cdp': 'customer data platforms',\n",
       " 'bdp': 'big data platform',\n",
       " 'dbas': 'database administration',\n",
       " 'go lang': 'go',\n",
       " 'soap api': 'soap',\n",
       " 'soap apis': 'soap',\n",
       " 'optical character recognition': 'ocr',\n",
       " 'mbse': 'mbse',\n",
       " 'pmis': 'project management information systems',\n",
       " 'mis': 'management information systems',\n",
       " 'ms': 'microsoft office',\n",
       " 'scm': 'supply chain management',\n",
       " 'dags': 'directed acyclic graph',\n",
       " 'vm': 'vmware',\n",
       " 'dsp': 'digital signal processing',\n",
       " 'udp': 'user defined functions',\n",
       " 'dbms': 'database management',\n",
       " 'database management systems': 'database management',\n",
       " 'rdbms design': 'relational database management systems',\n",
       " 'adfs': 'active directory federation services',\n",
       " 'ms project': 'microsoft project',\n",
       " 'gcp': 'google cloud platform'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load contractions skills\n",
    "with open('contractions_skills.json', 'r') as f:\n",
    "    contractions = json.load(f)\n",
    "\n",
    "contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_one_skills_jds(skills, contractions=contractions):\n",
    "    \n",
    "    for idx, skill in enumerate(skills):\n",
    "        if skill in contractions.keys():\n",
    "            skills[idx] = contractions[skill]\n",
    "\n",
    "            if type(skills[idx]) == list:\n",
    "                skills[idx] = contractions[skill][0]\n",
    "                for s in contractions[skill][1:]:\n",
    "                    skills.insert(idx, s)\n",
    "        \n",
    "    return skills\n",
    "\n",
    "total_skill_jbs = [change_one_skills_jds(skills) for skills in total_skill_jbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle word data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punctuation = string.punctuation\n",
    "\n",
    "def simple_tokenizer(skills):\n",
    "\n",
    "    tokenized_words = []\n",
    "    \n",
    "    for skill in skills:\n",
    "\n",
    "        pattern = r'[^\\w\\s#+./]'\n",
    "        cleaned_word = re.sub(pattern, ' ', skill)\n",
    "        \n",
    "        if cleaned_word:\n",
    "            tokenized_words.append(cleaned_word)\n",
    "    \n",
    "    \n",
    "    return tokenized_words\n",
    "\n",
    "# must handle simple tokenizer before\n",
    "# def lemmatize_skills(skills):\n",
    "\n",
    "#     for idx, skill in enumerate(skills):\n",
    "#         split_skill = skill.split()\n",
    "\n",
    "#         skill_lemma = [lemmatizer.lemmatize(word) for word in split_skill]\n",
    "\n",
    "#         skills[idx] = ' '.join(skill_lemma)\n",
    "\n",
    "#     return skills\n",
    "\n",
    "def post_process(skills):\n",
    "\n",
    "    new_skills = simple_tokenizer(skills)\n",
    "\n",
    "    return new_skills\n",
    "\n",
    "total_skill_jbs = [post_process(skills) for skills in total_skill_jbs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to train\n",
    "import json\n",
    "\n",
    "json_path = 'data/train/total_skill_jds.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(total_skill_jbs, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
